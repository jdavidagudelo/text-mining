{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#!pip install tensorflow_datasets\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/train.csv\"\n",
    "TEST_DATA_URL = \"https://storage.googleapis.com/tf-datasets/titanic/eval.csv\"\n",
    "\n",
    "train_file_path = tf.keras.utils.get_file(\"train.csv\", TRAIN_DATA_URL)\n",
    "test_file_path = tf.keras.utils.get_file(\"eval.csv\", TEST_DATA_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'head' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!head {train_file_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare', 'class', 'deck', 'embark_town', 'alone']\n"
     ]
    }
   ],
   "source": [
    "# CSV columns in the input file.\n",
    "with open(train_file_path, 'r') as f:\n",
    "    names_row = f.readline()\n",
    "\n",
    "\n",
    "CSV_COLUMNS = names_row.rstrip('\\n').split(',')\n",
    "print(CSV_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [0, 1]\n",
    "LABEL_COLUMN = 'survived'\n",
    "\n",
    "FEATURE_COLUMNS = [column for column in CSV_COLUMNS if column != LABEL_COLUMN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(file_path):\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "      file_path,\n",
    "      batch_size=12, # Artificially small to make examples easier to show.\n",
    "      label_name=LABEL_COLUMN,\n",
    "      na_value=\"?\",\n",
    "      num_epochs=1,\n",
    "      ignore_errors=True)\n",
    "    return dataset\n",
    "\n",
    "raw_train_data = get_dataset(train_file_path)\n",
    "raw_test_data = get_dataset(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLES: \n",
      " OrderedDict([('sex', <tf.Tensor: id=14580, shape=(12,), dtype=string, numpy=\n",
      "array([b'male', b'male', b'female', b'male', b'female', b'female',\n",
      "       b'male', b'female', b'female', b'male', b'male', b'male'],\n",
      "      dtype=object)>), ('age', <tf.Tensor: id=14572, shape=(12,), dtype=float32, numpy=\n",
      "array([28., 35., 28., 46., 41.,  9., 28., 22., 28., 28., 28., 37.],\n",
      "      dtype=float32)>), ('n_siblings_spouses', <tf.Tensor: id=14578, shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 4, 1, 0, 0, 0, 0, 2])>), ('parch', <tf.Tensor: id=14579, shape=(12,), dtype=int32, numpy=array([0, 0, 0, 0, 2, 2, 1, 2, 0, 0, 0, 0])>), ('fare', <tf.Tensor: id=14577, shape=(12,), dtype=float32, numpy=\n",
      "array([ 7.896,  7.05 ,  7.229, 79.2  , 20.212, 31.275, 15.246, 49.5  ,\n",
      "        7.75 ,  7.896,  8.05 ,  7.925], dtype=float32)>), ('class', <tf.Tensor: id=14574, shape=(12,), dtype=string, numpy=\n",
      "array([b'Third', b'Third', b'Third', b'First', b'Third', b'Third',\n",
      "       b'Third', b'First', b'Third', b'Third', b'Third', b'Third'],\n",
      "      dtype=object)>), ('deck', <tf.Tensor: id=14575, shape=(12,), dtype=string, numpy=\n",
      "array([b'unknown', b'unknown', b'unknown', b'B', b'unknown', b'unknown',\n",
      "       b'unknown', b'B', b'unknown', b'unknown', b'unknown', b'unknown'],\n",
      "      dtype=object)>), ('embark_town', <tf.Tensor: id=14576, shape=(12,), dtype=string, numpy=\n",
      "array([b'Southampton', b'Southampton', b'Cherbourg', b'Cherbourg',\n",
      "       b'Southampton', b'Southampton', b'Cherbourg', b'Cherbourg',\n",
      "       b'Queenstown', b'Cherbourg', b'Southampton', b'Southampton'],\n",
      "      dtype=object)>), ('alone', <tf.Tensor: id=14573, shape=(12,), dtype=string, numpy=\n",
      "array([b'y', b'y', b'y', b'y', b'n', b'n', b'n', b'n', b'y', b'y', b'y',\n",
      "       b'n'], dtype=object)>)]) \n",
      "\n",
      "LABELS: \n",
      " tf.Tensor([0 0 1 0 0 0 1 1 1 0 0 0], shape=(12,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "examples, labels = next(iter(raw_train_data)) # Just the first batch.\n",
    "print(\"EXAMPLES: \\n\", examples, \"\\n\")\n",
    "print(\"LABELS: \\n\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORIES = {\n",
    "    'sex': ['male', 'female'],\n",
    "    'class' : ['First', 'Second', 'Third'],\n",
    "    'deck' : ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J'],\n",
    "    'embark_town' : ['Cherbourg', 'Southhampton', 'Queenstown'],\n",
    "    'alone' : ['y', 'n']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_categorical_data(data, categories):\n",
    "    \"\"\"Returns a one-hot encoded tensor representing categorical values.\"\"\"\n",
    "  \n",
    "    # Remove leading ' '.\n",
    "    data = tf.strings.regex_replace(data, '^ ', '')\n",
    "    # Remove trailing '.'.\n",
    "    data = tf.strings.regex_replace(data, r'\\.$', '')\n",
    "  \n",
    "    # ONE HOT ENCODE\n",
    "    # Reshape data from 1d (a list) to a 2d (a list of one-element lists)\n",
    "    data = tf.reshape(data, [-1, 1])\n",
    "    # For each element, create a new list of boolean values the length of categories,\n",
    "    # where the truth value is element == category label\n",
    "    data = tf.equal(categories, data)\n",
    "    # Cast booleans to floats.\n",
    "    data = tf.cast(data, tf.float32)\n",
    "  \n",
    "    # The entire encoding can fit on one line:\n",
    "    # data = tf.cast(tf.equal(categories, tf.reshape(data, [-1, 1])), tf.float32)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14574, shape=(12,), dtype=string, numpy=\n",
       "array([b'Third', b'Third', b'Third', b'First', b'Third', b'Third',\n",
       "       b'Third', b'First', b'Third', b'Third', b'Third', b'Third'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_tensor = examples['class']\n",
    "class_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['First', 'Second', 'Third']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "class_categories = CATEGORIES['class']\n",
    "class_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14599, shape=(12, 3), dtype=float32, numpy=\n",
       "array([[0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_class = process_categorical_data(class_tensor, class_categories)\n",
    "processed_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of batch:  12\n",
      "Number of category labels:  3\n",
      "Shape of one-hot encoded tensor:  (12, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of batch: \", len(class_tensor.numpy()))\n",
    "print(\"Number of category labels: \", len(class_categories))\n",
    "print(\"Shape of one-hot encoded tensor: \", processed_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_continuous_data(data, mean):\n",
    "    # Normalize data\n",
    "    data = tf.cast(data, tf.float32) * 1/(2*mean)\n",
    "    return tf.reshape(data, [-1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEANS = {\n",
    "    'age' : 29.631308,\n",
    "    'n_siblings_spouses' : 0.545455,\n",
    "    'parch' : 0.379585,\n",
    "    'fare' : 34.385399\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14572, shape=(12,), dtype=float32, numpy=\n",
       "array([28., 35., 28., 46., 41.,  9., 28., 22., 28., 28., 28., 37.],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_tensor = examples['age']\n",
    "age_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=14608, shape=(12, 1), dtype=float32, numpy=\n",
       "array([[0.472],\n",
       "       [0.591],\n",
       "       [0.472],\n",
       "       [0.776],\n",
       "       [0.692],\n",
       "       [0.152],\n",
       "       [0.472],\n",
       "       [0.371],\n",
       "       [0.472],\n",
       "       [0.472],\n",
       "       [0.472],\n",
       "       [0.624]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_continuous_data(age_tensor, MEANS['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(features, labels):\n",
    "  \n",
    "    # Process categorial features.\n",
    "    for feature in CATEGORIES.keys():\n",
    "        features[feature] = process_categorical_data(features[feature],\n",
    "                                                 CATEGORIES[feature])\n",
    "\n",
    "    # Process continuous features.\n",
    "    for feature in MEANS.keys():\n",
    "        features[feature] = process_continuous_data(features[feature],\n",
    "                                                MEANS[feature])\n",
    "  \n",
    "    # Assemble features into a single tensor.\n",
    "    features = tf.concat([features[column] for column in FEATURE_COLUMNS], 1)\n",
    "  \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = raw_train_data.map(preprocess).shuffle(500)\n",
    "test_data = raw_test_data.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=14775, shape=(12, 24), dtype=float32, numpy=\n",
       " array([[1.   , 0.   , 0.81 , 0.   , 0.   , 0.386, 1.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.405, 0.   , 0.   , 0.189, 0.   , 1.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.472, 0.   , 0.   , 0.123, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 1.   , 1.   , 0.   ],\n",
       "        [0.   , 1.   , 0.692, 0.   , 6.586, 0.577, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [1.   , 0.   , 0.27 , 0.   , 0.   , 0.117, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [0.   , 1.   , 0.354, 0.   , 0.   , 0.113, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 1.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.472, 2.75 , 1.317, 0.37 , 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [0.   , 1.   , 0.405, 0.   , 2.634, 0.243, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 1.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 1.   ],\n",
       "        [1.   , 0.   , 0.439, 0.   , 0.   , 0.117, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.54 , 0.   , 0.   , 0.115, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [0.   , 1.   , 0.472, 0.   , 0.   , 0.48 , 0.   , 1.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ],\n",
       "        [1.   , 0.   , 0.523, 0.   , 0.   , 0.113, 0.   , 0.   , 1.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   , 0.   ,\n",
       "         0.   , 0.   , 0.   , 0.   , 1.   , 0.   ]], dtype=float32)>,\n",
       " <tf.Tensor: id=14776, shape=(12,), dtype=int32, numpy=array([1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0])>)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples, labels = next(iter(train_data))\n",
    "\n",
    "examples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(input_dim, hidden_units=[100]):\n",
    "    \"\"\"Create a Keras model with layers.\n",
    "\n",
    "  Args:\n",
    "    input_dim: (int) The shape of an item in a batch. \n",
    "    labels_dim: (int) The shape of a label.\n",
    "    hidden_units: [int] the layer sizes of the DNN (input layer first)\n",
    "    learning_rate: (float) the learning rate for the optimizer.\n",
    "\n",
    "  Returns:\n",
    "    A Keras model.\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(input_dim,))\n",
    "    x = inputs\n",
    "\n",
    "    for units in hidden_units:\n",
    "        x = tf.keras.layers.Dense(units, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape, output_shape = train_data.output_shapes\n",
    "\n",
    "input_dimension = input_shape.dims[1] # [0] is the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "53/53 [==============================]: 0.6329 - accuracy: 0.666 - 1s 506ms/step - loss: 0.6715 - accuracy: 0.666 - 1s 341ms/step - loss: 0.6531 - accuracy: 0.703 - 1s 259ms/step - loss: 0.6420 - accuracy: 0.743 - 1s 210ms/step - loss: 0.6585 - accuracy: 0.647 - 1s 177ms/step - loss: 0.6567 - accuracy: 0.650 - 1s 153ms/step - loss: 0.6540 - accuracy: 0.666 - 1s 135ms/step - loss: 0.6452 - accuracy: 0.678 - 1s 122ms/step - loss: 0.6394 - accuracy: 0.686 - 1s 111ms/step - loss: 0.6406 - accuracy: 0.666 - 1s 102ms/step - loss: 0.6367 - accuracy: 0.674 - 1s 95ms/step - loss: 0.6398 - accuracy: 0.659 - 1s 88ms/step - loss: 0.6462 - accuracy: 0.63 - 1s 83ms/step - loss: 0.6436 - accuracy: 0.64 - 1s 78ms/step - loss: 0.6390 - accuracy: 0.64 - 1s 74ms/step - loss: 0.6360 - accuracy: 0.65 - 1s 71ms/step - loss: 0.6339 - accuracy: 0.66 - 1s 67ms/step - loss: 0.6353 - accuracy: 0.66 - 1s 65ms/step - loss: 0.6340 - accuracy: 0.66 - 1s 62ms/step - loss: 0.6282 - accuracy: 0.67 - 1s 60ms/step - loss: 0.6256 - accuracy: 0.68 - 1s 57ms/step - loss: 0.6270 - accuracy: 0.68 - 1s 55ms/step - loss: 0.6223 - accuracy: 0.68 - 1s 54ms/step - loss: 0.6176 - accuracy: 0.69 - 1s 52ms/step - loss: 0.6188 - accuracy: 0.69 - 1s 50ms/step - loss: 0.6175 - accuracy: 0.68 - 1s 49ms/step - loss: 0.6158 - accuracy: 0.69 - 1s 48ms/step - loss: 0.6132 - accuracy: 0.70 - 1s 47ms/step - loss: 0.6074 - accuracy: 0.70 - 1s 45ms/step - loss: 0.6063 - accuracy: 0.70 - 1s 44ms/step - loss: 0.6042 - accuracy: 0.70 - 1s 43ms/step - loss: 0.6027 - accuracy: 0.70 - 1s 42ms/step - loss: 0.6054 - accuracy: 0.70 - 1s 41ms/step - loss: 0.6033 - accuracy: 0.70 - 1s 41ms/step - loss: 0.6009 - accuracy: 0.70 - 1s 40ms/step - loss: 0.5993 - accuracy: 0.70 - 1s 39ms/step - loss: 0.5974 - accuracy: 0.70 - 1s 38ms/step - loss: 0.5955 - accuracy: 0.70 - 1s 38ms/step - loss: 0.5918 - accuracy: 0.71 - 1s 37ms/step - loss: 0.5904 - accuracy: 0.71 - 1s 36ms/step - loss: 0.5897 - accuracy: 0.71 - 2s 36ms/step - loss: 0.5882 - accuracy: 0.71 - 2s 35ms/step - loss: 0.5869 - accuracy: 0.71 - 2s 35ms/step - loss: 0.5849 - accuracy: 0.72 - 2s 34ms/step - loss: 0.5854 - accuracy: 0.72 - 2s 34ms/step - loss: 0.5869 - accuracy: 0.72 - 2s 33ms/step - loss: 0.5852 - accuracy: 0.72 - 2s 33ms/step - loss: 0.5865 - accuracy: 0.71 - 2s 32ms/step - loss: 0.5867 - accuracy: 0.71 - 2s 32ms/step - loss: 0.5828 - accuracy: 0.72 - 2s 32ms/step - loss: 0.5807 - accuracy: 0.72 - 2s 31ms/step - loss: 0.5795 - accuracy: 0.72 - 2s 31ms/step - loss: 0.5784 - accuracy: 0.72 - 2s 31ms/step - loss: 0.5784 - accuracy: 0.7257\n",
      "Epoch 2/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.4595 - accuracy: 0.83 - ETA: 0s - loss: 0.5201 - accuracy: 0.75 - ETA: 0s - loss: 0.5065 - accuracy: 0.76 - ETA: 0s - loss: 0.4960 - accuracy: 0.78 - ETA: 0s - loss: 0.4898 - accuracy: 0.78 - 0s 5ms/step - loss: 0.4884 - accuracy: 0.7895\n",
      "Epoch 3/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.4123 - accuracy: 0.75 - ETA: 0s - loss: 0.4587 - accuracy: 0.83 - ETA: 0s - loss: 0.4643 - accuracy: 0.81 - ETA: 0s - loss: 0.4592 - accuracy: 0.82 - ETA: 0s - loss: 0.4507 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4535 - accuracy: 0.8134\n",
      "Epoch 4/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3959 - accuracy: 0.75 - ETA: 0s - loss: 0.4527 - accuracy: 0.82 - ETA: 0s - loss: 0.4444 - accuracy: 0.81 - ETA: 0s - loss: 0.4374 - accuracy: 0.82 - ETA: 0s - loss: 0.4395 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4378 - accuracy: 0.8150\n",
      "Epoch 5/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3902 - accuracy: 0.75 - ETA: 0s - loss: 0.4428 - accuracy: 0.82 - ETA: 0s - loss: 0.4302 - accuracy: 0.82 - ETA: 0s - loss: 0.4306 - accuracy: 0.81 - ETA: 0s - loss: 0.4350 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4301 - accuracy: 0.8166\n",
      "Epoch 6/20\n",
      "53/53 [==============================] - ETA: 1s - loss: 0.3863 - accuracy: 0.75 - ETA: 0s - loss: 0.4256 - accuracy: 0.83 - ETA: 0s - loss: 0.4277 - accuracy: 0.82 - ETA: 0s - loss: 0.4217 - accuracy: 0.81 - ETA: 0s - loss: 0.4243 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4251 - accuracy: 0.8166\n",
      "Epoch 7/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3819 - accuracy: 0.75 - ETA: 0s - loss: 0.4327 - accuracy: 0.82 - ETA: 0s - loss: 0.4197 - accuracy: 0.83 - ETA: 0s - loss: 0.4167 - accuracy: 0.82 - ETA: 0s - loss: 0.4244 - accuracy: 0.81 - 0s 5ms/step - loss: 0.4210 - accuracy: 0.8198\n",
      "Epoch 8/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3789 - accuracy: 0.75 - ETA: 0s - loss: 0.4289 - accuracy: 0.82 - ETA: 0s - loss: 0.4156 - accuracy: 0.83 - ETA: 0s - loss: 0.4164 - accuracy: 0.82 - 0s 5ms/step - loss: 0.4174 - accuracy: 0.8214\n",
      "Epoch 9/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3769 - accuracy: 0.75 - ETA: 0s - loss: 0.4192 - accuracy: 0.83 - ETA: 0s - loss: 0.4120 - accuracy: 0.83 - ETA: 0s - loss: 0.4133 - accuracy: 0.83 - ETA: 0s - loss: 0.4092 - accuracy: 0.82 - ETA: 0s - loss: 0.4174 - accuracy: 0.82 - 0s 6ms/step - loss: 0.4142 - accuracy: 0.8246\n",
      "Epoch 10/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3745 - accuracy: 0.83 - ETA: 0s - loss: 0.4355 - accuracy: 0.82 - ETA: 0s - loss: 0.4041 - accuracy: 0.84 - ETA: 0s - loss: 0.4164 - accuracy: 0.83 - ETA: 0s - loss: 0.4069 - accuracy: 0.83 - ETA: 0s - loss: 0.4024 - accuracy: 0.83 - 0s 7ms/step - loss: 0.4111 - accuracy: 0.8262\n",
      "Epoch 11/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3730 - accuracy: 0.83 - ETA: 0s - loss: 0.4332 - accuracy: 0.82 - ETA: 0s - loss: 0.4071 - accuracy: 0.84 - ETA: 0s - loss: 0.4133 - accuracy: 0.83 - ETA: 0s - loss: 0.4057 - accuracy: 0.82 - ETA: 0s - loss: 0.4029 - accuracy: 0.83 - 0s 7ms/step - loss: 0.4084 - accuracy: 0.8278\n",
      "Epoch 12/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3720 - accuracy: 0.83 - ETA: 0s - loss: 0.4308 - accuracy: 0.82 - ETA: 0s - loss: 0.3981 - accuracy: 0.84 - ETA: 0s - loss: 0.4102 - accuracy: 0.83 - ETA: 0s - loss: 0.4026 - accuracy: 0.82 - ETA: 0s - loss: 0.3964 - accuracy: 0.83 - 0s 7ms/step - loss: 0.4059 - accuracy: 0.8309\n",
      "Epoch 13/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3716 - accuracy: 0.83 - ETA: 0s - loss: 0.4177 - accuracy: 0.83 - ETA: 0s - loss: 0.4013 - accuracy: 0.84 - ETA: 0s - loss: 0.4077 - accuracy: 0.83 - ETA: 0s - loss: 0.3978 - accuracy: 0.83 - ETA: 0s - loss: 0.3934 - accuracy: 0.83 - 0s 7ms/step - loss: 0.4033 - accuracy: 0.8309\n",
      "Epoch 14/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3699 - accuracy: 0.83 - ETA: 0s - loss: 0.4259 - accuracy: 0.83 - ETA: 0s - loss: 0.3986 - accuracy: 0.84 - ETA: 0s - loss: 0.4047 - accuracy: 0.83 - ETA: 0s - loss: 0.3975 - accuracy: 0.83 - ETA: 0s - loss: 0.3954 - accuracy: 0.83 - ETA: 0s - loss: 0.4024 - accuracy: 0.83 - 0s 7ms/step - loss: 0.4008 - accuracy: 0.8325\n",
      "Epoch 15/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3707 - accuracy: 0.83 - ETA: 0s - loss: 0.4237 - accuracy: 0.83 - ETA: 0s - loss: 0.3902 - accuracy: 0.84 - ETA: 0s - loss: 0.4014 - accuracy: 0.83 - ETA: 0s - loss: 0.3904 - accuracy: 0.83 - ETA: 0s - loss: 0.3988 - accuracy: 0.83 - 0s 7ms/step - loss: 0.3985 - accuracy: 0.8325\n",
      "Epoch 16/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3711 - accuracy: 0.83 - ETA: 0s - loss: 0.4218 - accuracy: 0.83 - ETA: 0s - loss: 0.3878 - accuracy: 0.84 - ETA: 0s - loss: 0.3949 - accuracy: 0.84 - ETA: 0s - loss: 0.3877 - accuracy: 0.83 - ETA: 0s - loss: 0.3964 - accuracy: 0.83 - 0s 7ms/step - loss: 0.3963 - accuracy: 0.8325\n",
      "Epoch 17/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3709 - accuracy: 0.83 - ETA: 0s - loss: 0.4093 - accuracy: 0.83 - ETA: 0s - loss: 0.3919 - accuracy: 0.85 - ETA: 0s - loss: 0.3889 - accuracy: 0.84 - ETA: 0s - loss: 0.3897 - accuracy: 0.84 - ETA: 0s - loss: 0.3844 - accuracy: 0.84 - ETA: 0s - loss: 0.3944 - accuracy: 0.83 - 0s 7ms/step - loss: 0.3941 - accuracy: 0.8341\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - ETA: 2s - loss: 0.3719 - accuracy: 0.83 - ETA: 0s - loss: 0.4177 - accuracy: 0.83 - ETA: 0s - loss: 0.3831 - accuracy: 0.85 - ETA: 0s - loss: 0.3934 - accuracy: 0.84 - ETA: 0s - loss: 0.3859 - accuracy: 0.83 - ETA: 0s - loss: 0.3848 - accuracy: 0.83 - ETA: 0s - loss: 0.3900 - accuracy: 0.83 - 0s 8ms/step - loss: 0.3920 - accuracy: 0.8357\n",
      "Epoch 19/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3721 - accuracy: 0.83 - ETA: 0s - loss: 0.3911 - accuracy: 0.85 - ETA: 0s - loss: 0.3876 - accuracy: 0.85 - ETA: 0s - loss: 0.3815 - accuracy: 0.84 - 0s 5ms/step - loss: 0.3901 - accuracy: 0.8373\n",
      "Epoch 20/20\n",
      "53/53 [==============================] - ETA: 2s - loss: 0.3723 - accuracy: 0.83 - ETA: 0s - loss: 0.4137 - accuracy: 0.83 - ETA: 0s - loss: 0.3730 - accuracy: 0.86 - ETA: 0s - loss: 0.3760 - accuracy: 0.85 - ETA: 0s - loss: 0.3812 - accuracy: 0.84 - ETA: 0s - loss: 0.3762 - accuracy: 0.84 - ETA: 0s - loss: 0.3892 - accuracy: 0.83 - 0s 8ms/step - loss: 0.3883 - accuracy: 0.8373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fd1dfe3dd8>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(input_dimension)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     22/Unknown - 0s 133ms/step - loss: 0.7832 - accuracy: 0.583 - 0s 70ms/step - loss: 0.6111 - accuracy: 0.666 - 0s 50ms/step - loss: 0.5632 - accuracy: 0.72 - 0s 39ms/step - loss: 0.5418 - accuracy: 0.70 - 0s 33ms/step - loss: 0.5353 - accuracy: 0.71 - 0s 29ms/step - loss: 0.5366 - accuracy: 0.70 - 0s 26ms/step - loss: 0.4842 - accuracy: 0.75 - 0s 24ms/step - loss: 0.4696 - accuracy: 0.75 - 0s 22ms/step - loss: 0.4918 - accuracy: 0.73 - 0s 21ms/step - loss: 0.4808 - accuracy: 0.74 - 0s 20ms/step - loss: 0.4635 - accuracy: 0.75 - 0s 19ms/step - loss: 0.4848 - accuracy: 0.75 - 0s 18ms/step - loss: 0.4870 - accuracy: 0.74 - 0s 17ms/step - loss: 0.4804 - accuracy: 0.74 - 0s 17ms/step - loss: 0.4710 - accuracy: 0.75 - 0s 16ms/step - loss: 0.4771 - accuracy: 0.76 - 0s 16ms/step - loss: 0.4687 - accuracy: 0.75 - 0s 16ms/step - loss: 0.4636 - accuracy: 0.76 - 0s 15ms/step - loss: 0.4563 - accuracy: 0.77 - 0s 15ms/step - loss: 0.4508 - accuracy: 0.77 - 0s 15ms/step - loss: 0.4454 - accuracy: 0.78 - 0s 15ms/step - loss: 0.4426 - accuracy: 0.78 - 0s 15ms/step - loss: 0.4426 - accuracy: 0.7879Test Loss 0.4425579776818102, Test Accuracy 0.7878788113594055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_data)\n",
    "print('Test Loss {0}, Test Accuracy {1}\\n'.format(test_loss, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted survival: 67.53%  | Actual outcome:  DIED\n",
      "Predicted survival: 37.30%  | Actual outcome:  DIED\n",
      "Predicted survival: 99.11%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 79.45%  | Actual outcome:  DIED\n",
      "Predicted survival: 13.62%  | Actual outcome:  DIED\n",
      "Predicted survival: 80.49%  | Actual outcome:  DIED\n",
      "Predicted survival: 32.00%  | Actual outcome:  SURVIVED\n",
      "Predicted survival: 13.41%  | Actual outcome:  DIED\n",
      "Predicted survival: 13.02%  | Actual outcome:  DIED\n",
      "Predicted survival: 58.34%  | Actual outcome:  SURVIVED\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_data)\n",
    "\n",
    "# Show some results\n",
    "for prediction, survived in zip(predictions[:10], list(test_data)[0][1][:10]):\n",
    "  print(\"Predicted survival: {:.2%}\".format(prediction[0]),\n",
    "        \" | Actual outcome: \",\n",
    "        (\"SURVIVED\" if bool(survived) else \"DIED\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
